{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "directory ./data already exists\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "#import cPickle as pickle\n",
    "import pickle\n",
    "\n",
    "train_size = 9800\n",
    "test_size = 200\n",
    "img_size = 75\n",
    "size = 5 #Size of the objects in pixels\n",
    "\n",
    "question_size = 11 ##6 for one-hot vector of color, 2 for question type, 3 for question subtype\n",
    "\"\"\"Answer : [yes, no, rectangle, circle,  r, g, b, o, k, y]\"\"\"\n",
    "\n",
    "nb_questions = 10 #number of question per image\n",
    "dirs = './data'\n",
    "\n",
    "colors = [\n",
    "    (0,0,255),##r\n",
    "    (0,255,0),##g\n",
    "    (255,0,0),##b\n",
    "    (0,156,255),##o\n",
    "    (128,128,128),##k\n",
    "    (0,255,255)##y\n",
    "]\n",
    "\n",
    "try:\n",
    "    os.makedirs(dirs)\n",
    "except:\n",
    "    print('directory {} already exists'.format(dirs))\n",
    "    \n",
    "img = np.ones((img_size,img_size,3)) * 255\n",
    "\n",
    "def center_generate(objects):\n",
    "    while True:\n",
    "        pas = True\n",
    "        center = np.random.randint(0+size, img_size - size, 2)        \n",
    "        if len(objects) > 0:\n",
    "            for name,c,shape in objects:\n",
    "                if ((center - c) ** 2).sum() < ((size * 2) ** 2):\n",
    "                    pas = False\n",
    "        if pas:\n",
    "            return center"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To add a new figure on sort-of-CLEVR database was necesary to create it _*(cv2.ellipse())*_  as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.5, 74.5, 74.5, -0.5)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP4AAAD8CAYAAABXXhlaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAABEVJREFUeJzt3Vtu00AYgNEYdacspOpCutbwwsXCpLlgj+N850hIPFRt\nivg0f+zJeDqfzyeg5dveLwAYT/gQJHwIEj4ECR+ChA9Bwocg4UOQ8CHobfDPs00Qtjdd+wIrPgQJ\nH4KED0HChyDhQ5DwIUj4ECR8CBI+BAkfgoQPQcKHIOFDkPAhSPgQJHwIEj4ECR+ChA9Bwocg4UOQ\n8CFo9PHaDPbx8fH77+/v7zu+Ep6JFR+ChA9B0/k89OE2nqSzovkYvxZvB16CJ+kAS8KHIKP+wWwx\n3l9i7D8soz6wJHwIEj4ECR+ChA9Bwocg4UOQ8CHIBp4DGLlp519s5DkcG3iAJeFDkFH/YOzV5wZG\nfWBJ+BAkfAgSPgQJH4KED0HChyD38Q/M8dpc4D4+sCR8CDLqvzgPzUwy6gNLwocgoz68HqM+sCR8\nCBI+BAkfgoQPQcKHIOFDkPAhSPgQJHwIEj4ECR+ChA9Bwocg4UOQ8CFI+BAkfAgSPgQJH4Le9n4B\nnE6nz9nZiN+dR8r2rPgQ5HjtvXxePQH5D1MA93G8NrAkfAhycW+ke8Z72JAVH4KED0HChyDhQ5Dw\nIcgGnq2tfSXfZh6us4EHWBI+BAkfgoQPQcKHIOFDkPAhSPgQJHwIEj4ECR+ChA9Bwocg4UOQ8CFI\n+BAkfAgSPgQJH4KED0HChyDhQ5DjtUd69KhtR2pzH8drA0vChyDhQ5DwIUj4EOSq/jOYX+2vXMGf\nZr/z2P+DBa7qA0vChyCjPuubHtyodIm3Avcy6gNLwoegt71fAC9i7fH+0vc29q/Cig9Bwocg4UOQ\n8CFI+BDkqv7Gput7KTZ1tmeKf7DiQ5DwIcioz+O23LRzy8+0medhVnwIEj4EGfV53HzUHjX2G+9X\nYcWHIOFDkPAhSPgQJHwIEj4ECR+C3MdnHVve03/Se/d77Fie+59/Fis+BAkfgoz6rO+WGdSn7HZl\nxYcg4UOQUZ99GO93ZcWHIOFDkPAhSPgQJHwIEj4ECR+ChA9Bwocg4UOQ8CHIXv2NeT49z8iKD0HC\nhyDhQ5DwIUj4ECR8CBI+BAkfgoQPQcKHIOFDkPAhSPgQ5NN58KAjPwzIig9Bwocg4UOQ8CFI+BAk\n/Kc2/fwD6xI+BAkfgmzg2c09I/wtX3vg3SQMZ8WHIOFDkFF/qC2v0M+/t7Gfr1nxIUj4ECR8CBI+\nBAkfgoQPQcKHIOFDkA08m9vjY7U28/A1Kz4ECR+CjPqbm4/ao8Z+4z1fs+JDkPAhSPgQJHwIEj4E\nCR+ChA9B7uMPteU9fffuuZ0VH4KED0FG/d3cMpr/ejtgjGddVnwIEj4EGfWfmhGfbVjxIUj4ECR8\nCBI+BAkfgkZf1d/jrGngL1Z8CBI+BAkfgoQPQcKHIOFDkPAhSPgQJHwIEj4ECR+ChA9Bwocg4UOQ\n8CFI+BAkfAgSPgQJH4KED0HChyDhQ5DwIegHpxx9hyDS2g8AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f38134c5b00>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "objects = []\n",
    "img = np.ones((img_size,img_size,3)) * 255\n",
    "for color_id,color in enumerate(colors):  \n",
    "    center = center_generate(objects)\n",
    "    x=random.random()\n",
    "    #Range chaged: \n",
    "    #rectangle if random.random()<0.33, \n",
    "    #circle if 0.33<random.random()<0.66, \n",
    "    #ellipse ifrandom.random()<0.33\n",
    "    if x<0.33:\n",
    "        start = (center[0]-size, center[1]-size)\n",
    "        end = (center[0]+size, center[1]+size)\n",
    "        cv2.rectangle(img, start, end, color, -1)\n",
    "        objects.append((color_id,center,'r'))\n",
    "    elif x>0.33 and x<0.66:\n",
    "        center_ = (center[0], center[1])\n",
    "        cv2.circle(img, center_, size, color, -1)\n",
    "        objects.append((color_id,center,'c'))\n",
    "    else:\n",
    "        center_ = (center[0], center[1])\n",
    "        axes=(size+2, size-2)\n",
    "        angle=int(90)\n",
    "        start=int(0)\n",
    "        end=int(360)\n",
    "        cv2.ellipse(img, center_, axes, angle, start, end, color, -1)#New Figure: ellipse\n",
    "        objects.append((color_id,center,'e'))\n",
    "plt.imshow(img[:,:,(2,1,0)].astype(np.uint8))\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Then code for question creation also was chaged:\n",
    "#### First, for non-relational questions, new condition was added in order to insert the new figure in an answer. In this case the position in the answer vector was 4: Answer : [yes, no, rectangle, circle, ellipse r, g, b, o, k, y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.  1.  0.  0.  0.  0.  1.  0.  1.  0.  0.]\n",
      "color: 1\n",
      "subtype: 0\n",
      "answer: 2\n"
     ]
    }
   ],
   "source": [
    "rel_questions = []\n",
    "norel_questions = []\n",
    "rel_answers = []\n",
    "norel_answers = []\n",
    "\n",
    "#question_size = 11 ##6 for one-hot vector of color, 2 for question type, 3 for question subtype\n",
    "\"\"\"Non-relational questions\"\"\"\n",
    "question = np.zeros((question_size))\n",
    "color = random.randint(0,5)\n",
    "question[color] = 1\n",
    "question[6] = 1\n",
    "subtype = random.randint(0,2)\n",
    "question[subtype+8] = 1\n",
    "\"\"\"Answer : [yes, no, rectangle, circle, ellipse r, g, b, o, k, y]\"\"\"\n",
    "if subtype == 0:\n",
    "    \"\"\"query shape->rectangle/circle\"\"\"\n",
    "    if objects[color][2] == 'r':\n",
    "        answer = 2\n",
    "    elif objects[color][2] == 'c':# Here\n",
    "        answer = 3\n",
    "    else:\n",
    "        answer = 4# and Here\n",
    "elif subtype == 1:\n",
    "    \"\"\"query horizontal position->yes/no\"\"\"\n",
    "    if objects[color][1][0] < img_size / 2:\n",
    "        answer = 0\n",
    "    else:\n",
    "        answer = 1\n",
    "\n",
    "elif subtype == 2:\n",
    "    \"\"\"query vertical position->yes/no\"\"\"\n",
    "    if objects[color][1][1] < img_size / 2:\n",
    "        answer = 0\n",
    "    else:\n",
    "        answer = 1\n",
    "print(question)\n",
    "print(\"color:\",color)\n",
    "print(\"subtype:\",subtype)\n",
    "print(\"answer:\", answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The same was changed for relational questions. Position 4 in answer vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.  0.  0.  0.  1.  0.  0.  1.  1.  0.  0.]\n",
      "color: 4\n",
      "subtype: 0\n",
      "answer: 4\n"
     ]
    }
   ],
   "source": [
    "#question_size = 11 ##6 for one-hot vector of color, 2 for question type, 3 for question subtype\n",
    "\n",
    "\"\"\"Relational questions\"\"\"\n",
    "question = np.zeros((question_size))\n",
    "color = random.randint(0,5)\n",
    "question[color] = 1\n",
    "question[7] = 1\n",
    "subtype = random.randint(0,2)\n",
    "question[subtype+8] = 1\n",
    "rel_questions.append(question)\n",
    "\n",
    "if subtype == 0:\n",
    "    \"\"\"closest-to->rectangle/circle\"\"\"\n",
    "    my_obj = objects[color][1]\n",
    "    dist_list = [((my_obj - obj[1]) ** 2).sum() for obj in objects]\n",
    "    dist_list[dist_list.index(0)] = 999\n",
    "    closest = dist_list.index(min(dist_list))\n",
    "    if objects[closest][2] == 'r':\n",
    "        answer = 2\n",
    "    elif objects[closest][2] == 'c':# Here\n",
    "        answer = 3\n",
    "    else:\n",
    "        answer = 4# Here\n",
    "                \n",
    "elif subtype == 1:\n",
    "    \"\"\"furthest-from->rectangle/circle\"\"\"\n",
    "    my_obj = objects[color][1]\n",
    "    dist_list = [((my_obj - obj[1]) ** 2).sum() for obj in objects]\n",
    "    furthest = dist_list.index(max(dist_list))\n",
    "    if objects[furthest][2] == 'r':\n",
    "        answer = 2\n",
    "    elif objects[furthest][2] == 'c':# Here\n",
    "        answer = 3\n",
    "    else:\n",
    "        answer = 4# and Here\n",
    "\n",
    "elif subtype == 2:\n",
    "    \"\"\"count->1~6\"\"\"\n",
    "    my_obj = objects[color][2]\n",
    "    count = -1\n",
    "    for obj in objects:\n",
    "        if obj[2] == my_obj:\n",
    "            count +=1 \n",
    "    answer = count+4\n",
    "print(question)\n",
    "print(\"color:\",color)\n",
    "print(\"subtype:\",subtype)\n",
    "print(\"answer:\",answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This changes was added to _*sort_of_clevr_generator.py*_ code to generate the entire database. Aditionally, in _*translator.py*_ the answer sheet variable was changed, adding _*'ellipse'*_ in fourth position, according to previous modifications: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# In translator.py:\n",
    "\n",
    "#answer_sheet = ['yes', 'no', 'rectangle', 'circle', 'ellipse', '1', '2', '3', '4', '5', '6']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now, after training and creating the model (Test set: Relation accuracy=76% and Non-relation accuracy: 99%), is posible to test diferent images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f38114686d8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run main.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data...\n",
      "processing data...\n",
      "READY TO TEST\n"
     ]
    }
   ],
   "source": [
    "#Loading data\n",
    "def load_data():\n",
    "    print('loading data...')\n",
    "    dirs = './data'\n",
    "    filename = os.path.join(dirs,'sort-of-clevr.pickle')\n",
    "    with open(filename, 'rb') as f:\n",
    "        train_datasets, test_datasets = pickle.load(f)\n",
    "    rel_train = []\n",
    "    rel_test = []\n",
    "    norel_train = []\n",
    "    norel_test = []\n",
    "    print('processing data...')\n",
    "\n",
    "    for img, relations, norelations in train_datasets:\n",
    "        img = np.swapaxes(img,0,2)\n",
    "        for qst,ans in zip(relations[0], relations[1]):\n",
    "            rel_train.append((img,qst,ans))\n",
    "        for qst,ans in zip(norelations[0], norelations[1]):\n",
    "            norel_train.append((img,qst,ans))\n",
    "\n",
    "    for img, relations, norelations in test_datasets:\n",
    "        img = np.swapaxes(img,0,2)\n",
    "        for qst,ans in zip(relations[0], relations[1]):\n",
    "            rel_test.append((img,qst,ans))\n",
    "        for qst,ans in zip(norelations[0], norelations[1]):\n",
    "            norel_test.append((img,qst,ans))\n",
    "    \n",
    "    return (rel_train, rel_test, norel_train, norel_test)\n",
    "\n",
    "rel_train, rel_test, norel_train, norel_test = load_data()\n",
    "#Take a few seconds\n",
    "\n",
    "random.shuffle(rel_train)\n",
    "random.shuffle(norel_train)\n",
    "random.shuffle(rel_test)\n",
    "random.shuffle(norel_test)\n",
    "\n",
    "def cvt_data_axis(data):\n",
    "    img = [e[0] for e in data]\n",
    "    qst = [e[1] for e in data]\n",
    "    ans = [e[2] for e in data]\n",
    "    return (img,qst,ans)\n",
    "\n",
    "rel_train = cvt_data_axis(rel_train)\n",
    "rel_test = cvt_data_axis(rel_test)\n",
    "norel_train = cvt_data_axis(norel_train)\n",
    "norel_test = cvt_data_axis(norel_test)\n",
    "\n",
    "model = RN(args)\n",
    "\n",
    "model_dirs = './model'\n",
    "bs = args.batch_size\n",
    "input_img = torch.FloatTensor(bs, 3, 75, 75)\n",
    "input_qst = torch.FloatTensor(bs, 11)\n",
    "label = torch.LongTensor(bs)\n",
    "\n",
    "if args.cuda:\n",
    "    model.cuda()\n",
    "    input_img = input_img.cuda()\n",
    "    input_qst = input_qst.cuda()\n",
    "    label = label.cuda()\n",
    "\n",
    "input_img = Variable(input_img)\n",
    "input_qst = Variable(input_qst)\n",
    "label = Variable(label)\n",
    "\n",
    "model.train()\n",
    "\n",
    "def tensor_data(data, i):\n",
    "    img = torch.from_numpy(np.asarray(data[0][bs*i:bs*(i+1)]))\n",
    "    qst = torch.from_numpy(np.asarray(data[1][bs*i:bs*(i+1)]))\n",
    "    ans = torch.from_numpy(np.asarray(data[2][bs*i:bs*(i+1)]))\n",
    "\n",
    "    input_img.data.resize_(img.size()).copy_(img)\n",
    "    input_qst.data.resize_(qst.size()).copy_(qst)\n",
    "    label.data.resize_(ans.size()).copy_(ans)\n",
    "\n",
    "batch_idx=0 #Normally is \"for batch_idx in range(len(rel_train[0]) // bs)\"\n",
    "tensor_data(rel_train, batch_idx)\n",
    "accuracy_rel = model.train_(input_img, input_qst, label)\n",
    "\n",
    "tensor_data(norel_train, batch_idx)\n",
    "accuracy_norel = model.train_(input_img, input_qst, label)\n",
    "\n",
    "checkpoint = torch.load('model/epoch_RN_20.pth')\n",
    "model.load_state_dict(checkpoint)\n",
    "\n",
    "print('READY TO TEST')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NON-RELATIONAL QUESTION\n",
      "Question orange shape?\n",
      "[ 0.  0.  0.  1.  0.  0.  1.  0.  1.  0.  0.]\n",
      "Answer rectangle\n",
      "2\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP4AAAD8CAYAAABXXhlaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAABHlJREFUeJzt3UtuGkEUQNF05J1mIZYXkrWSSWy1hKMGO/2puueMMkCh\nJevqPegCltvt9gNo+Xn2BQDHEz4ECR+ChA9Bwocg4UOQ8CFI+BAkfAh6Ofj5HBOE/S1bDzDxIUj4\nECR8CBI+BAkfgoQPQcKHIOFDkPAhSPgQJHwIEj4ECR+ChA9Bwocg4UOQ8CFI+BAkfAgSPgQJH4KE\nD0HChyDhQ5DwIUj4ECR8CBI+BAkfgoQPQcKHIOFDkPAhSPgQ9HL2BXBhv5dzn//X7dznn5iJD0HC\nhyDhQ5DwIUj4ECR8CBI+BAkfgoQPQcKHIOFDkPAhSPgQJHwIEj4ECR+ChA9Bwocg4UOQ8CFI+BAk\nfAgSPgQJH4KED0HChyDhQ5DwIUj4ECR8CBI+BC2326G/Qe4Hz2F/y9YDTHwIEj4ECR+ChA9Bwoeg\nl7Mv4Cxvb28f/359fT3xSuB4Jj4ECR+CpjzAs17j/xcvBxiIAzzAvWkm/h5T/jMmPwMw8YF7wocg\n4UOQ8CFI+BAkfAgSPgQJH4KGPsBz1KGdf3GYh4tygAe4J3wIGnrVX3NWHz5Y9YF7wocg4UOQ8CFI\n+BAkfAgSPgQJH4KmOcCz5uu1iXOAB7gnfAiactV/hB/NZGJWfeCe8CEou+rDxKz6wD3hQ5DwIUj4\nECR8CBI+BAkfgoQPQcKHIOFDkPAhSPgQJHwIejn7Ana3rD6odOwnEeGyTHwIEj4Ejb3qL5vfN/D8\n470cIMDEhyDhQ9B4q/6z6/13/n9rP5My8SFI+BAkfAgSPgQJH4LGe1cfdrRs/wjNl90u9ENSJj4E\nCR+Cxln19z64s/WcDvNMZc+V/tnnPOMlgIkPQcKHoHFW/fdV+8iV33o/lTPW+6sy8SFI+BA0zqoP\nXzDCer++xqPe4TfxIcjEZ2rrCXrV6e8+PnAI4UPQeKv++t76Hvf03bsnwMSHIOFD0Hir/toja7lP\n2PHXI++e+yIOYFrCh6CxV/1HWO95wpXW8T2Z+BAkfAgSPgQJH4KED0HChyDhQ5DwIWj+AzzwqfWZ\n/MahnTUTH4KED0FWfSb07Edrtx4/30sBEx+ChA9BVn0msed35s93B8DEhyDhQ5DwIUj4ECR8CBI+\nBAkfgtzHZ2Bn/N79HPf0TXwIEj4EWfUZ2HrVPmrtH3e9XzPxIUj4ECR8CBI+BAkfgoQPQcKHIOFD\nkAM8TGLPwzxzHNpZM/EhSPgQNNyqv+x8JPs231YX9MgfcY6P136ViQ9BwoegS6/6e6/1zzynlwCz\naf9BTXwIEj4EXW7VP2O9hxoTH4KED0GXWPVHWO/fr9G7+8zAxIcg4UPQJVb99fp81bXfis9MTHwI\nEj4ECR+ChA9Bl3hzb23rTTRfxAHfZ+JDkPAh6HKr/harOHyfiQ9Bwocg4UOQ8CFI+BAkfAgSPgQJ\nH4KOPsBz0a/ZgBYTH4KED0HChyDhQ5DwIUj4ECR8CBI+BAkfgoQPQcKHIOFDkPAhSPgQJHwIEj4E\nCR+ChA9Bwocg4UOQ8CFI+BAkfAj6A/vwfguLuoZPAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f37df008160>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from translator import idx_to_question, idx_to_answer\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "n = np.random.randint(0,bs)\n",
    "tensor_data(norel_test, batch_idx)\n",
    "output = model(input_img, input_qst)\n",
    "pred = output.data.max(1)[1]\n",
    "pred2=pred.cpu().numpy()\n",
    "pred2= np.expand_dims(pred2,axis=1)\n",
    "pred = torch.from_numpy(pred2)\n",
    "print(\"NON-RELATIONAL QUESTION\")\n",
    "plt.imshow((input_img[n].data.cpu().numpy().transpose(1,2,0)[:,:,(2,1,0)]*255).astype(np.uint8))\n",
    "plt.axis('off')\n",
    "print(\"Question\",idx_to_question(input_qst[n].data.cpu().numpy()))\n",
    "print(input_qst[n].data.cpu().numpy())\n",
    "print(\"Answer\", idx_to_answer(pred[n].cpu().numpy()[0]))\n",
    "print(pred[n].cpu().numpy()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RELATIONAL QUESTION\n",
      "Question gray count?\n",
      "[ 0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  1.]\n",
      "Answer 2\n",
      "6\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP4AAAD8CAYAAABXXhlaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAABGVJREFUeJzt3UFum1AUQNFSZaddSOSFdK3uqJUlEmFcAx/uOeMo9iBX\n7xl+zHS/338ALT+PfgPA/oQPQcKHIOFDkPAhSPgQJHwIEj4ECR+CPnZ+PccEYXvT0g+Y+BAkfAgS\nPgQJH4KED0HChyDhQ5DwIUj4ECR8CBI+BAkfgoQPQcKHIOFDkPAhSPgQJHwIEj4ECR+ChA9Bwocg\n4UOQ8CFI+BC095N0Vrndbpv97s/Pz81+N4zOxIcg4UPQdL/v+hzLL19sy5V+LR8BuAAPzQTmhA9B\nh13VH2m9hxoTH4KED0G7XtW/3W673kL4X67wc1Ku6gNzwoegww7wjHpV33rPBVj1gTnhQ5DwIUj4\nECR8CBri33K/4xt44CWu6gNzwoegoVd94CVWfWBu6K/XhlOaFgfu6960oZv4ECR8CLLqw6u2XOnX\nvubKjwAmPgQJH4Ks+rDGEev9Bkx8CBI+BFn1N3H0Ouhk9FudYb1/fI9PXOE38SFI+BBk1Yclj6vz\nqGu/AzzAEuFDkFX/x+oLonB6Jj4ECR+CLr/qr70Iu/TzPgrEPfMH4Bt4gBEJH4IuuepvuWm5A8Ci\nE/xhmPgQJHwIEj4ECR+ChA9Bwocg4UPQZe7jH/1QkxPcuoV/THwIEj4EXWbVP+Jr0az3nJWJD0HC\nhyDhQ5DwIUj4ECR8CBI+BAkfgi5zgOfRlod5nju042QPYzPxIUj4EHTJVf/R2gefOH9PgYkPQcKH\noMuv+s8Yfr3//fBZ5Nfob5YzMPEhSPgQNN333XPtqV/5/eZTRj4O1C3+QZn4ECR8CLLqH+Xd6/13\nrP1FVn1gTvgQJHwIEj4ECR+ChA9Bwocg9/H3tNe9+++4p1/hPj4wJ3wIsuofxZFdtmPVB+aED0HC\nhyDhQ5DwIUj4ECR8CBI+BDnAMwJfr817OcADzAkfgqz6Z+Chmaxj1QfmhA9BVn24Hqs+MCd8CBI+\nBAkfgoQPQcKHIOFDkPAhSPgQJHwIEj4ECR+ChA9Bwocg4UOQ8CFI+BAkfAgSPgQJH4KED0HChyDh\nQ5DwIUj4EPRx9BvgPaaHh6fcPbCIBSY+BAkfgqz6JzAtPwNx9c/7ONBm4kOQ8CHIqj+wtSv+q7/b\n2t9j4kOQ8CFI+BAkfAgSPgQJH4KED0HChyAHeAaz5aGdZ17TYZ4GEx+CTPzBPE7cvaa/Kd9j4kOQ\n8CFI+BAkfAgSPgQJH4KED0HChyAHeAb292DNFgd5HNppM/EhSPgQZNU/gWfWcv9hxxomPgQJH4Ks\n+hdhvWcNEx+ChA9Bwocg4UOQ8CFI+BAkfAgSPgQJH4KED0HChyDhQ5DwIUj4ECR8CBI+BAkfgoQP\nQcKHIOFDkPAhSPgQJHwIEj4ECR+ChA9Bwocg4UOQ8CFI+BAkfAj62Pn1pp1fD/iCiQ9Bwocg4UOQ\n8CFI+BAkfAgSPgQJH4KED0HChyDhQ5DwIUj4ECR8CBI+BAkfgoQPQcKHIOFDkPAhSPgQJHwIEj4E\n/QF9kpJ2YOW0PAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f381146e4e0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "n = np.random.randint(0,bs)\n",
    "tensor_data(rel_test, batch_idx)\n",
    "output = model(input_img, input_qst)\n",
    "pred = output.data.max(1)[1]\n",
    "pred2=pred.cpu().numpy()\n",
    "pred2= np.expand_dims(pred2,axis=1)\n",
    "pred = torch.from_numpy(pred2)\n",
    "print(\"RELATIONAL QUESTION\")\n",
    "plt.imshow((input_img[n].data.cpu().numpy().transpose(1,2,0)[:,:,(2,1,0)]*255).astype(np.uint8))\n",
    "plt.axis('off')\n",
    "print(\"Question\",idx_to_question(input_qst[n].data.cpu().numpy()))\n",
    "print(input_qst[n].data.cpu().numpy())\n",
    "print(\"Answer\", idx_to_answer(pred[n].cpu().numpy()[0]))\n",
    "print(pred[n].cpu().numpy()[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
